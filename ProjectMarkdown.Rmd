---
title: "Predictive Sales Analytics of My Family's Business"
#subtitle: "add subtitle if you want"
author: "*Parsa Keyvani*"
header-includes:
    - \usepackage{setspace}\doublespacing
output: 
  pdf_document:
    toc: yes
    number_sections: yes
date: "`r format(Sys.Date(), '%B %Y')`"  
---


```{r, include=FALSE}
# you can set chunk options globally so that you don't have to specify each time. 
knitr::opts_chunk$set(out.width='60%', fig.asp=.7, fig.path='Figs/', fig.align = 'center', warning=FALSE, message=FALSE, collapse = TRUE)

# and this sets the number of digits
options(digits=4)
```

```{r, include=FALSE}
# activate all packages that you will need for sure, for example 
library(tidyverse)
library(readxl)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(jalcal)
library(tsibble)
library(ggpubr)
library(feasts)
library(lubridate)
library(gridExtra)
library(tinytex) # required to produce pdf documents
library(forecast)
library(vars)
library(tseries)
library(urca)
library(mFilter)
library(GGally)
library(fable)
library(knitr)
```

# Introduction
In this research project I use data analytics tools to find sales insights and predict the sales performance of my family's business. The company gathers the data in a daily time-series fashion where each row corresponds to an order being placed. The data include 12 datasets: 6 datasets for sales data and another 6 datasets for returns data. The data values are in Farsi language and dates are in Jalali format. The dependent variable to be studied is Total Sales and the independent variables that might help with obtaining better forecasts are: 

* __The Buying Power:__ The buying power of the consumer is largely dependent on their income.  The amount of the product which the consumer is willing and able to purchase also depends on the type of goods. Since school and office supplies are considered normal goods, a consumer will buy more if his income increases.
* __The Number of Customers (Lagged):__ The number of customers positively affect the sales of a company since more consumers suggest more demand for the company's products. 
* __Discounts:__ a price discount provides a monetary gain that incentivizes consumers to purchase the product. Consumers also perceive a higher level of savings for a product when a higher price discount is provided. Therefore, a higher price discount leads to higher sales.
* __Sale Return (Lagged):__ as total sales increase, sales return also increases because as sales increase, there is a higher possibility of returns. 

__Note:__ due to the presence of large missing values and abnormalities for some of the independent variables, the project did not use all the desired independent variables for analysis. 

The methods employed for forecasting the time series data are exponential smoothing (SNAIVE), ARIMA, and multiple regression with seasonal decomposition, and piecewise_linear model. The exponential smoothing is used to indicate the baseline model performance, and other models are used to predict future sales.

## Importance of Demand Forecasting for a Stationery Business
Demand forecasting is the process of estimating the future sales of a particular product or service to customers over a defined period, using historical sales data to make informed business decisions (Intuit, 2022). It could either be carried out as a bottom-up approach where judgmental approaches are used or conducted using advanced methods that statisticians have developed. General forecasting approaches include judgmental, experimental, relational/causal, and time-series approaches. Moreover, demand forecasting will contribute to the following enhancements in my family’s business.

1. __Improved Inventory Management__
Demand for the company’s stationery products exhibits seasonality. Hence accurate demand forecasting will help prevent large stocks in the inventory. Utilizing demand forecasting in this project will also reduce the risk of damages or losses of products in the inventory.

2. __Improved Planning and Control__
A good demand forecast helps in the better allocation of resources. For instance, it allows better planning of the supply of raw materials and other inputs, price, and promotional activities. It will control the number of internal costs such as storage cost and wastage and external costs such as loss of customer perception, opportunity cost, loss of market share. 

3. __Improved future decision making__
Demand forecasting will allow a better understanding of the consumers' behavior and will allow decision-makers to respond in advance to unfavorable situations and prepare a more robust and accurate growth plan.


# Literature Review	
## Market Demand for Stationery Products
The market for stationery products is constantly growing, especially with the rise of technology, where consumers now seek convenient one-stop-shop options instead of selling one-product-category (Aurmanarom, 2010). However, a study has reported that the global demand for stationery products during 2016 and 2020 grew sluggishly as laptops, desktops, and smartphones replaced traditional stationery items (Market Research Company, 2022). Although short-term market growth does not seem promising, a recent market report conducted by Market Research Company forecasted the global stationery market to reach \$30 billion from its 2021 value at \$24 billion. Therefore, the long-term projections suggest steady demand from educational institutes and workplaces. Several studies were conducted to explain the long-term increase in sales demand:

1. Rising educational programs can fuel demand for stationery products. Rising inclination towards higher education and government initiatives boost the educational sector and direct the market on a positive trend.
2. The demand for stationery products is likely to remain high across the corporate sector due to its increasing scale of businesses and its necessity to maintain records regarding employees, turnover, profits, and other crucial aspects. Hence, the demand for products, such as file boxes, folders, binders, clipboards, and other similar products for documentation is likely to sustain; however, increased reliance on digital records may restrict the growth of the stationery market.
3. Customization in design, personalized printing, and comprehensive marketing strategies bridge the gap between the manufacturers and the consumers, which opens new doors for market expansion.
4. The proportion of young population is projected to increase with an estimated 4 percent growth from 2020 to 2035, which suggests a steady increase in demand for stationery products (Frey, 2021). 

The studies expected growth to remain mainly concentrated across the developing countries, particularly in Asia. Countries such as India and China are extensively investing in primary and secondary educational programs to meet the population's requirements (Market Research Company, 2022). China's stationary market grew significantly over the past years and reached \$18 billion in 2019, and according to recent studies, the market is predicted to remain among the fastest-growing regional markets (Market Research Company, 2022). Similarly, Iran's stationery market is also growing. The stationery market reached $1 billion in 2017, with over 40% of the market being held by Iranian producers and the rest being imported mainly from China and Germany (Financial Tribune, 2017). Chinese products alone hold a 50% share of Iran's stationery imports as the variety, and low prices of Chinese stationery have made them popular among both importers and consumers (Financial Tribune, 2017). 

## Stationery Products Sale Forecast
For forecasting stationery products sales, relatively fewer studies are conducted. Most studies have focused on time series models, and predictions of the stationary product sales were made with support vector regression and methods alike. Economic indicators used for improved forecasting accuracy of stationery products sales include gross domestic product (GDP), consumer price index (CPI), interest rate, and unemployment rate. Other indicators such as the number of consumers, the price of related goods, product discounts, and the cost of the products are also used for forecasting the future demand for stationery products. The most relevant literature relating to forecasting product sales of my family’s business is the “_Applicability of Forecasting Models and Techniques for Stationery Business: A Case Study from Sri Lanka_” conducted by Dewmini Danushika Illeperuma and Thashika Rupasinghe from the University of Kelaniya. This paper presents a demand forecasting methodology for a stationery company in Sri Lanka. The data is collected and prepared as a monthly time series from April 2008 until April 2013. The demand for stationery products exhibits strong seasonality and cyclicality. Furthermore, the literature utilizes a combination of judgmental methods, quantitative methods, and Artificial Intelligence methods as the literature proved to have generated higher forecasting accuracy. Time series forecasting methods used in the literature are single exponential smoothing, Croston’s method, Moving average, Additive Winter, and ARIMA. Methods based on judgment are unaided judgment, prediction markets, and Delphi. Methods used for quantitative methods are extrapolation, quantitative analogies, and rule-based forecasting. Moreover, using all three methods, they built a model that produced a relatively low mean absolute percentage error (MAPE) that forecasts the sales of drawing books (Dewmini et al., 2013).


# Data and Time Series Characteristics
## Data Collection and Preprocessing
The data are extracted directly from the company and include 45 different variables from which we choose six total variables in this study. There are a total of 12 datasets which include 6 datasets for sales of the past 6 years (2016-2021) and another 6 datasets for the sales returns for the past 6 years. The data is recorded daily where each row indicates a purchase made by a customer. This is not ideal as we want each row to represent total sales made by customers in a day. We corrected this by summing the values of sales and returns datasets in each day so that each row would indicate one distinct day. Moreover, the variables of interest were translated from Farsi to English and the dates were also converted from Jalili to Gregorian. Additionally, in the raw data, the company's product names column includes more than 100 unique names because each product was differentiated by its color. This is not of our interest and to fix this for our analysis, we grouped and combined all the products and their respective colors into one product. After the modifications the 12 datasets were merged and converted from daily to monthly data. Our dependent variable is the company’s historical sales. And independent variables that will support our analysis and forecasting are: sales returned and the number of distinct customers. The company manufactures and sells four different products: binders, metal rings that are placed in the binders, clip boards, and file boxes. The variables of interest are prepared to give historical values of each product.

```{r include = FALSE}
sales_1395<-read_xlsx("Sales_Data/Sales_1395.xls")
sales_1396<-read_xlsx("Sales_Data/Sales_1396.xls")
sales_1397<-read_xlsx("Sales_Data/Sales_1397.xls")
sales_1398<-read_xlsx("Sales_Data/Sales_1398.xls")
sales_1399<-read_xlsx("Sales_Data/Sales_1399.xls")
sales_1400<-read_xlsx("Sales_Data/Sales_1400.xls")

returns_1395<-read_xlsx("Sales_Return/Returns_1395.xls")
returns_1396<-read_xlsx("Sales_Return/Returns_1396.xls")
returns_1397<-read_xlsx("Sales_Return/Returns_1397.xls")
returns_1398<-read_xlsx("Sales_Return/Returns_1398.xls")
returns_1399<-read_xlsx("Sales_Return/Returns_1399.xls")
returns_1400<-read_xlsx("Sales_Return/Returns_1400.xls")
IRNCPI<-read_csv("IRNCPI.csv")


#### Creating a function that selects, renames, and drops na's from the sales datasets.
sales_modify<- function (dataset) {
  dataset<-dataset %>%
    rename(Date = "تاريخ", 
           Product_Name= "نام كالا", 
           Unit_Price= "قيمت واحد",
           Total_Sales = "مبلغ كل",
           Discount = "تخفيف",
           Customer_Name= "نام مشترى",
           Commissions = "سهم واسطه") %>%
    transmute(Date = as.Date(Date, "%Y/%m/%d"), Product_Name, Unit_Price, 
              Total_Sales, Discount, Customer_Name, Commissions) %>%
    drop_na()
  return(dataset)
}

#### Using above function on the six datasets.
sales_1395 <- sales_modify(sales_1395)
sales_1396 <- sales_modify(sales_1396)
sales_1397 <- sales_modify(sales_1397)
sales_1398 <- sales_modify(sales_1398)
sales_1399 <- sales_modify(sales_1399)
sales_1400 <- sales_modify(sales_1400)

#### Creating a function that selects, renames, and drops na's from the returns datasets.
returns_modify<- function (dataset) {
  dataset<-dataset %>%
    rename(Date = "تاريخ",
           Total_Value_Returned= "مبلغ كل",
           Commissions_Returned = "سهم واسطه") %>%
    transmute(Date = as.Date(Date, "%Y/%m/%d"), Total_Value_Returned, 
              Commissions_Returned) %>%
    drop_na()
  return(dataset)
}


returns_1395 <- returns_modify(returns_1395)
returns_1396 <- returns_modify(returns_1396)
returns_1397 <- returns_modify(returns_1397)
returns_1398 <- returns_modify(returns_1398)
returns_1399 <- returns_modify(returns_1399)
returns_1400 <- returns_modify(returns_1400)


#### A function that converts Jalali dates to Gregorian dates for each dataset.
dates_modify<- function (dataset) {
  # Seperating Year, Month, Day from Date column.
  Year<-format(dataset$Date, format = "%Y")
  Month <-format(dataset$Date, format = "%m")
  Day <-format(dataset$Date, format = "%d")
  # Initializing an empty date tibble.
  date_tibble <- tibble(
    Date = as.Date(character()))
  # Converting Jalali dates to Gregorian dates.
  i <- 1
  while (i<=nrow(dataset)){
    date_tibble<- add_row(date_tibble, Date = jal2greg(Year[i], Month[i], Day[i]))
    i=i+1
  }
  # Adding Gregorian dates to the dataset and removing Jalili Date column.
  dataset<-dplyr::select(dataset,-Date)
  dataset <- tibble(date_tibble, dataset) 
  #dataset <- select(dataset,-Date)
  return(dataset)
}

sales_2016 <- dates_modify(sales_1395)
sales_2017 <- dates_modify(sales_1396)
sales_2018 <- dates_modify(sales_1397)
sales_2019 <- dates_modify(sales_1398)
sales_2020 <- dates_modify(sales_1399)
sales_2021 <- dates_modify(sales_1400)

returns_2016 <- dates_modify(returns_1395)
returns_2017 <- dates_modify(returns_1396)
returns_2018 <- dates_modify(returns_1397)
returns_2019 <- dates_modify(returns_1398)
returns_2020 <- dates_modify(returns_1399)
returns_2021 <- dates_modify(returns_1400)

# There were more than 200 unique product names in the dataset, but there are anly 4 product
#categories: Binder, MetalRing, File box, and clip board. Since they have different colors 
# and each data input did not exactly match one another, it was listed as 200 unique. Here, 
# I modified to have only 4 distinct product.
ProductNameModify<-function (dataset) {
  i<-1
  while (i<=nrow(dataset)){
    if (str_detect(dataset[i,2], "مقوا|چسب|جلد|كارت ليبل|كلاسور") && !str_detect(dataset[i,2], "تخته شاسى|قفل|جامجله اى")) {
      dataset[i,2]= "Binder"}
    else if (str_detect(dataset[i,2], "فيلتر|قفل|چفت")) {
      dataset[i,2]= "MetalRing"}
    else if (str_detect(dataset[i,2], "جامجله اى|پاكت|پوشه|فولدر|كيف|كلر بوك|ديوايدر|ML 310|فايل باكس")) {
      dataset[i,2]= "FileBox"}
    else if (str_detect(dataset[i,2], "Lexi |پك ملزومات")){
      dataset[i,2]= "other"}
    else if (str_detect(dataset[i,2], "زير دستى|تخته شاسى")) {
      dataset[i,2]= "ClipBoard"}
    i=i+1
  }
  return(dataset)
}

sales_2016<-ProductNameModify(sales_2016)
sales_2016<-sales_2016 %>%
  filter(Product_Name %in% c("Binder","MetalRing","FileBox","ClipBoard"))
sales_2017<-ProductNameModify(sales_2017)
sales_2017<-sales_2017 %>%
  filter(Product_Name %in% c("Binder","MetalRing","FileBox","ClipBoard"))
sales_2018<-ProductNameModify(sales_2018)
sales_2019<-ProductNameModify(sales_2019)
sales_2020<-ProductNameModify(sales_2020)
sales_2021<-ProductNameModify(sales_2021)

# joining sales datasets with the corresponding returns datasets to find the real sales
# after deducting the returns.
sales_returns_2016<-full_join(sales_2016, returns_2016, by="Date")
sales_returns_2017<-full_join(sales_2017, returns_2017, by="Date")
sales_returns_2018<-full_join(sales_2018, returns_2018, by="Date")
sales_returns_2019<-full_join(sales_2019, returns_2019, by="Date")
sales_returns_2020<-full_join(sales_2020, returns_2020, by="Date")
sales_returns_2021<-full_join(sales_2021, returns_2021, by="Date")


# Modifying the datasets so that each colomn represents sales for each day for each product. 
# Additionally, the total daily sales and total daily commissions are true values computed after 
# taking returns into account. We also added distinct customer column which is an integer representing
# the number of unique costumers in each day for each Product. total sales, unit price, total discount,
# and total commissions are converted from rials to USD using proper exchange rate for each year.

ToProperFormat<-function (dataset) {
  dataset<-dataset %>%
    group_by(Date,Product_Name) %>%
    mutate(Total_Value_Returned = replace(Total_Value_Returned, is.na(Total_Value_Returned), 0),
           Commissions_Returned = replace(Commissions_Returned, is.na(Commissions_Returned), 0)) %>%
    summarise(unit_price= median(Unit_Price),
              total_sales= sum(Total_Sales),
              tot_discount= sum(Discount), 
              tot_commissions= sum(Commissions),
              distinct_customers= length(unique(Customer_Name)),
              tot_sales_returned= sum(Total_Value_Returned))
  return(dataset)
}


true_sales_2016<-ToProperFormat(sales_returns_2016)
true_sales_2017<-ToProperFormat(sales_returns_2017)
true_sales_2018<-ToProperFormat(sales_returns_2018)
true_sales_2019<-ToProperFormat(sales_returns_2019)
true_sales_2020<-ToProperFormat(sales_returns_2020)
true_sales_2021<-ToProperFormat(sales_returns_2021)

# merging all the rows of all 6 datasets to produce one dataset.
merged_data<-rbind(true_sales_2016,true_sales_2017,true_sales_2018,
                   true_sales_2019,true_sales_2020,true_sales_2021)

# Converting the merged dataset to a tsibble.
merged_data_tsbl <- as_tsibble(merged_data, key=Product_Name, index=Date)

monthly_sales_returns<-merged_data_tsbl %>% 
  filter(year(Date)<2022) %>%
  index_by(year_month = yearmonth(Date)) %>%
  group_by(Product_Name) %>%
  summarise(total_sales= sum(total_sales),
            total_returned= sum(tot_sales_returned),
            total_customers= sum(distinct_customers)) %>%
  drop_na()
```


Graph 1 below shows the total sales with respect to each product. We can see that the 
product that generates the most revenue for the company is Metal rings. The graphs indicate 
strong seasonality in all the products. Additionally, there seems to be two cyclicalities in 
clip board sales: one in 2016 and another in 2020 with a sharp and unusual increase in sales. Similarly, there is a cyclicality in the sales of binders in 2022 with an unusal abropt increase in sales. Moreover, two products show clear trend. Metal ring sales have a clear upward trend and file box sales have a clear downward trend since 2016. For binder sales and clip board sales the graphs do not seem to show a clear trend. 

```{r echo=FALSE}
ggplot(monthly_sales_returns, aes(year_month, total_sales)) +
  facet_wrap(~Product_Name, scales = "free", ncol = 2) + geom_line() + labs(title = "Graph 1: Total Sales with Respect to Each Product")
```

__Note:__ Due to our time constraint, further analysis and forecasting in this project will examine metal ring sales as it generates the most revenue and therefore is the most important product for the company.


## Inflation Adjustment
Total sales and returned sales are measured in nominal Rials (Iranian currency). Since inflation is often a significant component of apparent growth, it is important to adjust these variables for inflation to uncover the real values. Additionally, deflation may stabilize the variance of random or seasonal fluctuations and highlight cyclical patterns in the data (Nau, 2020). Deflation is accomplished by dividing a monetary time series by a price index. Our monetary time series are metal ring sales and metal ring sales returned, and the price index is Iran's Consumer Price Index (CPI). CPI for Iran is collected from the Federal Reserve Bank of St. Louis (World Bank, 1960). The inflation adjustment has been applied to all the indicated variables. Graph 2 shows the adjusted for inflation values. After inflation adjustment, we can see that the trend for the variables has been to some extent decreased, which signifies that the remaining trend is real growth. Furthermore, the seasonal and cyclical patterns and the sales' magnitude stand out more clearly when displayed in real terms.


```{r include = FALSE}
IRNCPI_ts<- IRNCPI %>%
  as_tsibble(index = as.numeric(DATE),
             key = CPI) %>%
  index_by(year_month= yearmonth(DATE)) %>%
  summarise(year_month, CPI)

monthly_sales_returns<-left_join(monthly_sales_returns, IRNCPI_ts, by = "year_month")

i<-1
while (i<=nrow(monthly_sales_returns)){
  if (is.na(monthly_sales_returns[i,6])){
    monthly_sales_returns[i,6]= monthly_sales_returns[i-1,6]
  }
  i=i+1
}

# real values of the nominal vriables.
real_monthly_sales_returns<-monthly_sales_returns %>%
  mutate(real_sales= total_sales/CPI) %>%
  mutate(real_returned= total_returned/CPI)
```


    
```{r echo=FALSE}
p2<- real_monthly_sales_returns%>%
  filter(Product_Name=="MetalRing") %>%
  autoplot(total_customers)
p3<- real_monthly_sales_returns%>%
  filter(Product_Name=="MetalRing") %>%
  autoplot(real_returned)
p4<- real_monthly_sales_returns%>%
  filter(Product_Name=="MetalRing") %>%
  autoplot(real_sales)
grid.arrange(p4, p3,p2, nrow=3, ncol=1, top= "Graph 2: Selected Variables' Historical Values with Respect to Metal Ring")
```

## Box-Cox Transformation
The main use of variable transformation is to reduce changing variability and skewness and other distributional features that complicate analysis. Since our dependent variable as shown in Graph 2 have changing variablility over time, it is nessecery to correct this. Box-Cox transformation method is used to do so. For real sales, $\lambda_{optimal}=0.730$, which suggest that square root plus linear transformation would be the best transformation method. Therefore, the transformed series is shown in Graph 3. The graph shows that changing variability was reduced in real sales transformation, but it is not completely eliminated.


```{r include = FALSE}
real_monthly_sales_returns %>%
  filter(Product_Name == "MetalRing") %>%
  features(real_sales, features = guerrero) 

metalRing_real <- real_monthly_sales_returns %>%
  filter(Product_Name == "MetalRing") %>%
  mutate(real_sales_trans = box_cox(real_sales, 0.730))
```

    
```{r echo=FALSE}
p1<- real_monthly_sales_returns%>%
  filter(Product_Name=="MetalRing") %>%
  autoplot(real_sales)
p2<- metalRing_real%>%
  filter(Product_Name=="MetalRing") %>%
  autoplot(real_sales_trans)
grid.arrange(p1, p2, nrow=2,ncol=1, top= "Graph 3: Before and After Real Sales Transformation Adjustment")
```

## Time Series Decomposition
We use time series decomposition to better understand the series. The main objectives for a decomposition is to estimate seasonal effects that can be used to create and present seasonally adjusted values to better identify trends in the series. Since we already used Box_Cox transformation, we use additive decomposition on the transformed variables, which is computed below.  
$$ \text{y}_{t} = S_{t}+ T_{t}+R_{t}$$ Where ${y}_{t}= \text{data at period t}\\$, 
${T}_{t} = \text{ trend-cycle component at period t}]\\$, 
${S}_{t}= \text {seasonal component at period t}\\$,
${R}_{t} = \text {remainder component at period t}\\$

After decomposition, Graph 4 clearly dipicts an upward trend beginning from the late 2019, a strong seasonality, and some cyclicality.

    
```{r echo=FALSE}
dcmp<-metalRing_real %>%
  model(stl = STL(real_sales_trans))
components(dcmp) %>% autoplot() + labs(title = "Graph 4: Transformed Real Sales Decomposition")
```

## Seasonality and Autocorrelation
__Seasonality Observations:__
gg_subseries in Graph 5 confirm our observation of the presence of strong seasonality and trend in the variables. Furthermore, the plot indicate that sales were highest in May, October, and December and lowest in July of each year. 

    
```{r , fig.width = 7, echo=FALSE}
metalRing_real %>% 
  gg_subseries(real_sales_trans) + labs(title = "Graph 5: Transformed Real Sales Seasonal Plot")
```

__Autocorrelation Observations:__
Graph 6 shows a particularly high correlation between current values and their first, seventh, and eighth lags, which denotes strong positive autocorrelation and hints strong seasonality at those lags. Additionally, the autocorrelations for small lags tend to be somewhat large and positive, which signifies some trend in the data. Moreover, the autocorrelation seems to get smaller in larger lags, which implies that each observation is more positively associated with its recent past.


```{r echo=FALSE}
metalRing_real %>%
  ACF(real_sales_trans, lag_max = 24) %>%
  autoplot() + labs(title="real_sales_trans ACF") +labs(title = "Graph 6: Transformed Real Sales Correlogram ")
```

# Application of Forecasting Methods
```{r include=FALSE}
data<-metalRing_real %>%
  dplyr::select(real_sales_trans, real_returned,total_customers) %>%
  mutate(myindex = row_number(year_month),
         t_lin = myindex,
         t_19 = cumsum(as.numeric(myindex >= 43)))

train <- data %>%
  filter(year_month < yearmonth("2020 Nov"))

test <- data %>%
  filter(year_month >= yearmonth("2020 Nov"))

fit_data <- train %>%
  model(
    # Seasonal Naive
    Seasonal_naive=SNAIVE(real_sales_trans),
    # model 2
    stl_arima = decomposition_model(
      # does decomposition and models seasonal part
      STL(real_sales_trans, robust = TRUE),
      # models non-seasonal part using ARIMA
      ARIMA(season_adjust)),
    # model 3
    # models the y directly
    arima = ARIMA(real_sales_trans),
    # Model
    stl_lm1 = decomposition_model(
      # does decomposition and models seasonal part
      STL(real_sales_trans, robust = TRUE),
      # models non-seasonal part using multiple regression
      TSLM(season_adjust ~ trend() + real_returned + total_customers)),
    # model 4
    stl_lm2 = decomposition_model(
      # does decomposition and models seasonal part
      STL(real_sales_trans, robust = TRUE),
      # models non-seasonal part using multiple regression
      TSLM(season_adjust ~ trend() + real_returned + lag(real_returned,1) + lag(total_customers,1)+total_customers)),
    # linear:
    linear = TSLM(real_sales_trans ~ t_lin),
    # model 6
    piecewise_linear = TSLM(real_sales_trans ~ t_lin + t_19)
  )
fc_data <- fit_data %>%
  forecast(test)
```

In this section, we attempt to forecast metal rings' transformed real sales by using various forecasting models. The forecasting methods implemented are SNAIVE, ARIMA, Piecewise Linear model, and multiple regression models. Furthermore, the train test split ratio used in the project is 80:20. Since our series is strongly seasonal, our strategy is to forecast seasonal and non-seasonal components separately and then combine these forecasts to obtain forecasts for $y_t$, which is the transformed real sales of metal rings. Formally,

$$\hat{y_t} = \hat{S_t} + \hat{A_t}$$

$\hat{y_t}$ obtains forecasts of transformed real sales as the sum of forecasts of seasonal component ($\hat{S_t}$) and forecasts of seasonally adjusted component ($\hat{A_t}$).


Model 1: The SNAIVE model is used as our baseline model and models $y_t$ directly. This model is chosen to be compared with the performance of more sophisticated models. The SNAIVE model is also chosen because our series exhibits strong seasonality.

Model 2: For this model, we forecast $y_t$ by forecasting $S_t$ and $A_t$ separately by using decomposition_model() function. By default, this function uses SNAIVE() to forecast the seasonal part ($S_t$). And to fit a model for $A_t$, it uses an ARIMA framework.

Model 3: This model doesn’t forecast $S_t$ and $A_t$ separately, rather it models $y_t$
directly using ARIMA() with transformed_real_sales as its argument, which is $y_t$.

Model 4: this model forecasts $y_t$ by forecasting $S_t$ and $A_t$ separately by using decomposition_model() function. By default, this function uses SNAIVE() to forecast the seasonal part ($S_t$). model 4 uses a regression framework to fit a model for $A_t$. Since our dependent variable (Transformed Real Sales) has some linear trend we have included a trend variable such as:
$$ A_t = \beta_0 + \beta_1t + \beta_2\mathrm{realReturned} + \beta_3\mathrm{totalCustomers} + e_t$$ 
Model 5: Similar to Model 4, this model also uses decomposition_model() function to forecast St and uses a regression framework to fit a model for At. The difference between the two models is that this model also includes the first lag of the two independent variables in the regression shown below.
$$A_t = \beta_0 + \beta_1t + \beta_2\mathrm{realReturned} + \beta_3\mathrm{lagRealReturned} + \beta_4\mathrm{totalCustomers} + \beta_5\mathrm{lagTotalCustomers} +  e_t$$ 
Model 6 and 7: Model 6 uses a linear regression model with the main purpose of comparing with Model 7, which uses a piecewise linear regression model. As shown in Graph 4, we can see that the data has a clear upward trend starting from October of 2019 onwards. We placed a kink in October 2019 and used a piecewise linear model to better capture this behavior.
Model 6 is as shown below: 
$$\mathrm{transformedRealSales}_t = \beta_0 + \beta_1\mathrm{tLin}$$
And Model 7 is as shown below:
$$\mathrm{transformedRealSales}_t = \beta_0 + \beta_1\mathrm{tLin} + \beta_2\mathrm{t19Oct}$$

## Model Accuracy Analysis

```{r echo=FALSE}
fc_data %>%
  autoplot(level = NULL) +
  autolayer(data, color = "black") + labs(title = "Graph 7: Models' Performance on the Test set")
```

```{r echo=FALSE}
accuracy<-accuracy(fc_data, test)
kable(accuracy[1:7], caption = "Accuracy Results")
```

According to table 1, the best-performing model is stl_lm2, the 5th model in section 4 analysis. The
RMSE value for this model is the lowest, and the MAPE value shows only around a 13 percent error rate,
which indicates that the model is relatively accurate. Overall, we can say that multiple regression models
performed better than other models. Additionally, we can confirm that the piecewise linear model performed
significantly better than the linear model, suggesting that placing a kink in October 2019 resulted in a
more accurate prediction. Lastly, we can see that both Arima models performed worse than our baseline
model (seasonal_naive), indicating low prediction accuracy.


```{r echo=FALSE}
fit_data <- test %>%
  model(
    stl_lm2 = decomposition_model(
      # does decomposition and models seasonal part
      STL(real_sales_trans, robust = TRUE),
      # models non-seasonal part using multiple regression
      TSLM(season_adjust ~ trend() + real_returned + lag(real_returned,1)+ lag(total_customers,1)+total_customers))
  )

fitted(fit_data) %>%
  autoplot(.fitted, color = "red") +
  autolayer(data, real_sales_trans) + labs(title = "Graph 8: Best Performing Model on the Test Set")
```


# Conclusion
The goal of this paper was to predict my family’s business product sales to improve the company's sales performance. By analyzing and preparing the company’s data, producing visualizations, and building various forecasting models to predict the products' future sales, we were able to gain valuable insights. Additionally, we were able to build a model with 87 percent prediction accuracy that is 24 percent more accurate than the baseline model performance. This model will give the company a better understanding of the company’s sales historical pattern and will improve business decisions. In the future, I plan on expanding this project to give more insights about the company's sales and customers. Additionally, I plan to include more independent variables in my analyses, such as the nation's GDP and product sales discounts. I also plan to use the Vector Autoregression model (VAR) and other Machine Learning models to forecast the sales and come up with an even more accurate model. Lastly, I plan on expanding my analyses to all four products. 


# Bibliography

[1] Frey, William H. 2021. “What the 2020 Census Will Reveal about America: Stagnating Growth, an Aging Population, and Youthful Diversity.” Brookings (blog). January 11, 2021. https://www.brookings.edu/research/what-the-2020-census-will-reveal-about-america-stagnating-growth-an-aging-population-and-youthful-diversity/.

[2] Aurmanarom, C. (2010). An exploration of the impact of brand personality on consumer buying intentions toward specialist stationery products across age groups. https://ro.ecu.edu.au/theses_hons/1235

[3] “Stationery Market Analysis.” Market Research Company, n.d. Accessed February 28, 2022. https://www.factmr.com/report/stationery-market/toc.

[4] “Stationery Producers Reclaiming Iran’s $1b Market.” Financial Tribune, September 11, 2017. https://financialtribune.com/articles/economy-domestic-economy/72197/stationery-producers-reclaiming-iran-s-1b-market.

[5] Danushika Dewmini, Thashika Illeperuma, and Thashika Rupasinghe, “Applicability of Forecasting Models and Techniques for Stationery Business: A Case Study from Sri Lanka,” International Journal of Engineering Research 2 (November 1, 2013): 2319–6890.

[6] Inc, Intuit. n.d. “What Is Demand Forecasting?” Accessed March 1, 2022. https://www.tradegecko.com/ebooks/demand-forecasting.

[7] Nau, Robert. “Inflation Adjustment.” Fuqua School of Business, Duke University, 18 Aug. 2020, https://faculty.fuqua.duke.edu/~rnau/Decision411_2007/411infla.htm. 

[8] World Bank, “Consumer Price Index for Islamic Republic of Iran,” FRED, Federal Reserve Bank of St. Louis (FRED, Federal Reserve Bank of St. Louis, January 1, 1960), https://fred.stlouisfed.org/series/DDOE01IRA086NWDB.

